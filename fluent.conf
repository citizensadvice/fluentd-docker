<source>
  @type tail
  path /fluentd/incoming/*.log
  exclude_path ["/fluentd/incoming/fluent*.log"]
  pos_file "/fluentd/pos/docker.#{ENV['FLUENT_TAG']}.log.pos"
  tag "docker.#{ENV['FLUENT_TAG']}"
  @label @APPLOGS

  <parse>
    @type multi_format
    <pattern>
      format json
      types payload:string
      time_key timestamp
      keep_time_key true
      time_format %Y-%m-%dT%H:%M:%S.%NZ
    </pattern>
    <pattern>
      format none
    </pattern>
  </parse>
</source>

<label @APPLOGS>

  <filter **>
    @type grep
    <exclude>
      key path
      pattern /\/(status|readiness|liveness)/
    </exclude>
  </filter>

  <filter **>
    @type record_transformer

    # we partition by these so they must be removed from the record
    # otherwise HIVE will complain
    remove_keys application, datestamp
  </filter>

  # TODO:
  # docker.#{ENV['FLUENT_TAG']} does not
  # expand and
  # setting this to match **
  # causes stack overflow
  #
  # so what we do is match any incoming
  # streams having tag_parts.size == 4,
  # add the EC2 instance id to the tag so
  # tag_parts now has 5 elements and pass
  # on to the next matcher
  <match docker.*.*.* >
    @type ec2_metadata
    output_tag ${tag}.${instance_id}
  </match>

  <match **>
    @type s3

    s3_bucket "#{ENV['FLUENT_S3_BUCKET']}"
    s3_region "#{ENV['AWS_REGION']}"
    s3_object_key_format %{path}/${tag}_%{time_slice}_%{index}.json.%{file_extension}
    time_slice_format %Y%m%d%H%M
    path logs/application=${tag[2]}/datestamp=%Y%m%d

    <buffer tag,time>
       flush_interval 30m
       timekey 1800 # 1/2 hour partition
       timekey_wait 2m
       timekey_use_utc true
       flush_mode interval
       type file
       path /fluentd/s3_buffer
       flush_at_shutdown true
    </buffer>

    use_server_side_encryption AES256
    format json
   </match>

</label>
